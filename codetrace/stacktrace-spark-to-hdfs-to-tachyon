-> tachyon.hadoop.TachyonFileSystem.initialize(tachyon://localhost:19998/user/hobin/input/log4j.properties, Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml) [TachyonFileSystem.java:218]
    tachyon.hadoop.TachyonFileSystem.initialize(TachyonFileSystem.java:219)
    org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1411)
    org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
    org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1429)
    org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
    org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
    org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:176)
    org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:208)
    spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:52)
    spark.RDD.partitions(RDD.scala:168)
    spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:9)
    spark.RDD.partitions(RDD.scala:168)
    spark.SparkContext.runJob(SparkContext.scala:624)
    spark.RDD.count(RDD.scala:490)
    $line4.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:15)
    $line4.$read$$iwC$$iwC$$iwC.<init>(<console>:20)
    $line4.$read$$iwC$$iwC.<init>(<console>:22)
    $line4.$read$$iwC.<init>(<console>:24)
    $line4.$read.<init>(<console>:26)
    $line4.$read$.<init>(<console>:30)
    $line4.$read$.<clinit>(<console>)
    $line4.$eval$.<init>(<console>:11)
    $line4.$eval$.<clinit>(<console>)
    $line4.$eval.$export(<console>)
    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    java.lang.reflect.Method.invoke(Method.java:601)
    spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:629)
    spark.repl.SparkIMain$Request$$anonfun$10.apply(SparkIMain.scala:890)
    scala.tools.nsc.interpreter.Line$$anonfun$1.apply$mcV$sp(Line.scala:43)
    scala.tools.nsc.io.package$$anon$2.run(package.scala:25)
    java.lang.Thread.run(Thread.java:722)


-> tachyon.hadoop.TachyonFileSystem.open(tachyon://localhost:19998/user/hobin/input/log4j.properties, 65536) [TachyonFileSystem.java:269]
    tachyon.hadoop.TachyonFileSystem.open(TachyonFileSystem.java:270)
    org.apache.hadoop.fs.FileSystem.open(FileSystem.java:427)
    org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:86)
    org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:55)
    spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:71)
    spark.rdd.HadoopRDD.compute(HadoopRDD.scala:65)
    spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
    spark.RDD.iterator(RDD.scala:195)
    spark.rdd.MappedRDD.compute(MappedRDD.scala:12)
    spark.RDD.computeOrReadCheckpoint(RDD.scala:206)
    spark.RDD.iterator(RDD.scala:195)
    spark.scheduler.ResultTask.run(ResultTask.scala:76)
    spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
    spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
    java.util.concurrent.FutureTask.run(FutureTask.java:166)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    java.lang.Thread.run(Thread.java:722)


-> tachyon.hadoop.TFileInputStreamHdfs.read([B@677dc492, 0, 65536) [TFileInputStreamHdfs.java:157]
    tachyon.hadoop.TFileInputStreamHdfs.read(TFileInputStreamHdfs.java:158)
    java.io.DataInputStream.read(DataInputStream.java:100)
    org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
    org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
    org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
    spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
    scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
    spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
    spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
    spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
    spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
    spark.scheduler.ResultTask.run(ResultTask.scala:76)
    spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
    spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
    java.util.concurrent.FutureTask.run(FutureTask.java:166)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    java.lang.Thread.run(Thread.java:722)


-> tachyon.hadoop.TFileInputStreamHdfs.read([B@677dc492, 0, 65536) [TFileInputStreamHdfs.java:157]
    tachyon.hadoop.TFileInputStreamHdfs.read(TFileInputStreamHdfs.java:158)
    java.io.DataInputStream.read(DataInputStream.java:100)
    org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
    org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
    org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
    spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
    scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
    spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
    spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
    spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
    spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
    spark.scheduler.ResultTask.run(ResultTask.scala:76)
    spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
    spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
    java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
    java.util.concurrent.FutureTask.run(FutureTask.java:166)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
    java.lang.Thread.run(Thread.java:722)
